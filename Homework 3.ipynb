{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIS 399 Homework 3: Algorithmic Fairness\n",
    "\n",
    "## Sophia Trump\n",
    "\n",
    "In this homework, you will gain experience with tools for implementing classifiers that provide fairness guarantees. In part 2, you will try to get a fair classifier if you only have access to a normal classifier. In parts 3 and 4, you will get to explore the different outcomes when using different definitions of fairness for classifiers. You will also look at the tradeoffs between fairness and accuracy. \n",
    "\n",
    "All cells where code is required are marked with a \"YOUR CODE HERE\" comment. The point values for each code block are written in the header for the associated subsection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Importing Data (5 Points)\n",
    "Before working with the algorithms for fair classification, we must first import the dataset we wish to use. We will again be working with the \"Communities and Crime\" dataset from [UC Irvine's Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/communities+and+crime). It includes data about the different types of crimes among various communities, socioeconomic and racial data about each community, and information about the police force in each community.\n",
    "\n",
    "The algorithms will require that your data is split into 3 DataFrames:\n",
    "\n",
    "- `dataX`: The features of each instance, not including any protected attributes\n",
    "- `dataA`: The protected attributes of each instance\n",
    "- `dataY`: The label for each instance\n",
    "\n",
    "Currently, we provide you with 2 CSV files:\n",
    "\n",
    "- `communities.csv`, which contains all information for each instance\n",
    "- `communities_protected.csv`, which labels each column as 1 if the attribute is a protected feature, 2 if the attribute is the label for the instance, and 0 otherwise. In part 2, we will focus on only one of the sensitive features. In parts 3 and 4, we will use all 18 sensitive features for upholding our fairness metrics.\n",
    "\n",
    "Write code to generate the 3 Pandas DataFrames, `dataX`, `dataA` and `dataY`. Print the size of each dataframe when you are finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataX Shape: (1994, 104)\n",
      "dataA Shape: (1994, 18)\n",
      "dataY Shape: (1994, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Suppressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "## YOUR CODE HERE\n",
    "dataframe1 = pd.read_csv(\"communities.csv\")\n",
    "dataframe2 = pd.read_csv(\"communities_protected.csv\")\n",
    "\n",
    "#separate protected attributes, unprotected attributes, and labels into 3 separate lists\n",
    "protectedCol = [] \n",
    "unprotectedCol = [] \n",
    "label = []\n",
    "for i in range(0, len(dataframe1.columns.values), 1):\n",
    "    if(data2[i] == 0): #not protected\n",
    "        unprotectedCol.append(dataframe1.columns[i])\n",
    "    if(data2[i] == 1): #protected\n",
    "        protectedCol.append(dataframe1.columns[i]) \n",
    "    if(data2[i] == 2): #a label\n",
    "        label.append(dataframe1.columns[i])\n",
    "        \n",
    "#make the dataX, dataA, and dataY arrays by dropping by column label (as created in the previous step)\n",
    "dataX = dataframe1.drop(protectedCol, axis = 1)\n",
    "dataX = dataX.drop(label, axis = 1) #drop the label column\n",
    "\n",
    "dataA = dataframe1.drop(unprotectedCol, axis = 1)\n",
    "dataA = dataA.drop(label, axis = 1) #drop the label column\n",
    "\n",
    "dataY = dataframe1.drop(protectedCol, axis = 1)\n",
    "dataY = dataY.drop(unprotectedCol, axis = 1)\n",
    "            \n",
    "print('dataX Shape:', dataX.shape)\n",
    "print('dataA Shape:', dataA.shape)\n",
    "print('dataY Shape:', dataY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Two-Group Fairness via Post-processing (35 Points)\n",
    "\n",
    "In this section, you will implement a method of achieving a fair classifier \"from scratch\" by post-processing a generic linear regression classifier. This method is described in https://arxiv.org/abs/1610.02413 and was discussed in Lecture 10 (https://www.seas.upenn.edu/~cis399/files/lecture/l10.pdf). \n",
    "\n",
    "Here, you will train a classifier which approximately equalizes both True Positive Rate and False Positive Rate for two groups (which we generate for you), which is commonly referred to as the Equalized Odds criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Training a Real-Valued Predictor (5 points)\n",
    "\n",
    "Fairness postprocessing requires training a model which predicts real-valued scores (such as the estimated probability of a positive label) rather than just predicting 0 or 1. \n",
    "\n",
    "Use the Linear Regression package from SciKit-Learn to train a regression model on dataX and dataY. Generate predictions for dataY (called y_hat_score) and print them.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25785039]\n",
      " [0.20704865]\n",
      " [0.45755179]\n",
      " ...\n",
      " [0.65533497]\n",
      " [0.09814837]\n",
      " [0.73405048]]\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "logreg = LinearRegression().fit(dataX, dataY)\n",
    "y_hat_score = logreg.predict(dataX)\n",
    "print(y_hat_score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Binary Classification via Thresholding (5 points)\n",
    "\n",
    "Write a function (threshold_predictions) which takes in a set of predicted scores and a threshold, and converts the scores to 0/1 predictions (below or equal to threshold = 0, above threshold = 1). Print out your converted predictions using a threshold of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "def threshold_predictions(y_hat_score, threshold):\n",
    "    converted_predictions = []\n",
    "    for i in range(0, len(y_hat_score)):\n",
    "        if(y_hat_score[i] <= threshold):\n",
    "            converted_predictions.append(0)\n",
    "        else:\n",
    "            converted_predictions.append(1)\n",
    "    return converted_predictions\n",
    "\n",
    "y_hat_0_1 = threshold_predictions(y_hat_score, 0.5)\n",
    "print(y_hat_0_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: Computing TPR and FPR (5 points)\n",
    "\n",
    "Write functions which compute the true positive rate and false positive rate, given vectors for true labels (y) and binary predictions (y_hat). Returning to the confusion matrix from HW2, recall that FPR = B/(B+D) and TPR = A/(A+C):\n",
    "https://www.seas.upenn.edu/~cis399/HW2_CIS399.pdf\n",
    "\n",
    "Compute the TPR and FPR for your predictions from 2.2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7032590051457976\n",
      "0.05669737774627923\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "def true_positive_rate(y, y_hat):\n",
    "    true_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    #convert y to 1d array\n",
    "    y = y.values[:,:]\n",
    "    y = y.ravel()\n",
    "    for i in range(0, len(y)):\n",
    "        if((y[i] == 1) and (y_hat[i] == 1)): #true positive?\n",
    "            true_positives += 1\n",
    "        elif((y[i] == 1) and (y_hat[i] == 0)): #false negative?\n",
    "            false_negatives+= 1\n",
    "    return (true_positives)/(true_positives+false_negatives)\n",
    "        \n",
    "def false_positive_rate(y, y_hat):\n",
    "    false_positives = 0\n",
    "    true_negatives = 0\n",
    "    \n",
    "    #convert y to 1d array\n",
    "    y = y.values[:,:]\n",
    "    y = y.ravel()\n",
    "    \n",
    "    for i in range(0, len(y)):\n",
    "        if((y[i] == 0) and (y_hat[i] == 1)): #false positive?\n",
    "            false_positives += 1\n",
    "        elif((y[i] == 0) and (y_hat[i] == 0)): #true negative?\n",
    "            true_negatives += 1\n",
    "    return (false_positives)/(false_positives+true_negatives)\n",
    "\n",
    "print(true_positive_rate(dataY, y_hat_0_1))\n",
    "print(false_positive_rate(dataY, y_hat_0_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4: Computing ROC Curves (5 points)\n",
    "\n",
    "ROC (receiver operating characteristic) curves measure the tradeoff between true positive and false positive rates when thresholding a real-valued predictor: https://en.wikipedia.org/wiki/Receiver_operating_characteristic \n",
    "\n",
    "Write a function that takes in a set of {0,1} true labels (such as dataY), a set of [0,1] predictions (such as y_hat_score), and a single integer, `num_thresholds`, reprensting the number of thresholds. Evenly divide the range [0,1] into `num_thresolds` equally sized intervals. For each interval, use the bottom of the interval as a threshold,  threshold the real-valued predictions to {0,1} predictions (as in 2.2), and compute the TPR and FPR of the thresolded predictions.\n",
    "\n",
    "For example, if num_thresholds = 100, your thresholds should be 0.00, 0.01, 0.02, ... , 0.99.\n",
    "\n",
    "Compute arrays of TPR and FPR values using dataY and y_hat score with 100 thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "def compute_roc_curve(y, y_hat_score, num_thresholds):\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    \n",
    "    # evenly divide the range [0,1] into num_thresholds equally sized intervals\n",
    "    inc_by = 1/num_thresholds\n",
    "    steps = []\n",
    "    i = 0.00\n",
    "    while(i < 1):\n",
    "        steps.append(i)\n",
    "        i += inc_by\n",
    "        \n",
    "    for i in range(0, len(steps)):\n",
    "        y_hat_local = threshold_predictions(y_hat_score, steps[i]) #use the bottom of the interval as a threshold, threshold the real-valued predictions to {0,1} predictions (as in 2.2)\n",
    "        tpr.append(true_positive_rate(dataY, y_hat_local)) #compute TPR of the threshold predictions\n",
    "        fpr.append(false_positive_rate(dataY, y_hat_local)) #compute FPR of the threshold predictions\n",
    "    \n",
    "    return tpr, fpr\n",
    "\n",
    "tpr, fpr = compute_roc_curve(dataY, y_hat_score, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5: ROC Curve Comparison (5 points)\n",
    "\n",
    "The code below is copied from our solution to Homework 1 and splits the data into two groups (A and B), based on whether the proportion of black people in the community is greater than 50%. Run the cell below.\n",
    "\n",
    "Using the generated arrays (X_A, X_B, y_A, y_B) and your function from 2.4, produce a matplotlib plot showing the ROC curves for each group with 100 threshold values. Use your trained linear regression model for predictions. Your X axis should be FPR and your Y axis should be TPR. Refer to Homework 1 for a reminder on how to use matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL\n",
    "## DO NOT MODIFY\n",
    "\n",
    "def split_on_feature(dataX, dataY, dataA, column, thresh):\n",
    "    rows_A = []\n",
    "    rows_B = []\n",
    "    for i in range(dataX.shape[0]):\n",
    "        if dataA[i, column] < thresh:\n",
    "            rows_A.append(i)\n",
    "        else:\n",
    "            rows_B.append(i)\n",
    "    \n",
    "    X_A = dataX[rows_A, :]\n",
    "    X_B = dataX[rows_B, :]\n",
    "    y_A = dataY[rows_A]\n",
    "    y_B = dataY[rows_B]\n",
    "    \n",
    "    return X_A, X_B, y_A, y_B  \n",
    "\n",
    "\n",
    "# change 2 to whatever racepctblack is\n",
    "X_A, X_B, y_A, y_B = split_on_feature(dataX.values, dataY.values, dataA.values, 0, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6: Minimizing Unfairness (5 points)\n",
    "\n",
    "There are 10,000 possible pairs of thresholds of the form $(a,b)$ where $a$ is the threshold for A and $b$ is the threshold for B in data plotted above. Find and print out the pair which minimizes  $|TPR_A - TPR_B| + |FPR_A - FPR_B|$. You can think of this as finding points which are closest between the two ROC curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "print((min_unfairness_A_thresh, min_unfairness_B_thresh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7: Evaluating Accuracy (5 points)\n",
    "\n",
    "Compute the overall \"fair\" error when using the thresholds from 2.6 on their respective groups. Compare this to the minimum achievable error when using the single best threshold in {0.00, 0.01, 0.02, ... , 0.99} for both groups.\n",
    "\n",
    "As with HW1, you should calculate the percentage of labels that are misclassified as your error metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "print((min_err, fair_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Marginal Group Fairness via Cost-Sensitive Reduction (15 Points)\n",
    "\n",
    "In this section, you will implement models from Microsoft Research (MSR), which use cost-sensitive classification in order to generate classifiers which satisfy particular fairness metrics. The algorithm is derived in [A Reductions Approach to Fair Classification](https://arxiv.org/pdf/1803.02453.pdf) and was discussed in lecture: https://www.seas.upenn.edu/~cis399/files/lecture/l10.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Importing the MSR code (5 Points)\n",
    "The version of the MSR code has been provided in the same directory as this notebook. Run the following command to make sure that the notebook is able to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run this cell\n",
    "!python test_fairlearn.py\n",
    "\n",
    "import marginal_fair\n",
    "## Expected Output:\n",
    "# testing (DP, eps=0.100): ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: Marginal Fairness (5 Points)\n",
    "In this section, you will analyze a classifier that is marginally fair with respect to the protected attributes.\n",
    "\n",
    "The current implementation of the MSR code allows for one protected attribute at a time, so we have provided a file `marginal_fair.py` which generalizes the MSR code to allow for more than one protected attribute.\n",
    "\n",
    "At the bottom of `marginal_fair.py`, you will find a function `run_eps_single`, which runs this algorithm. The function takes in 4 arguments: `eps`, `x`, `a`, and `y`. `x`, `a`, and `y` correspond to `dataX`, `dataA`, and `dataY`, respectively, and `eps` is a parameter which measures the allowed statistical unfairness of a classifier (in this case, we are looking at false positive disparity rates).\n",
    "\n",
    "Using `run_eps_single`, get the predictions of the marginally fair classifier for `eps = 0.01` and report the overall error of this classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3: Pareto Curve for Marginally Fair Classifier (5 Points)\n",
    "By varying the parameter `eps`, construct a Pareto curve that measures the error of the classifier as the allowed fairness violation changes.\n",
    "\n",
    "Use the following values for `eps`: `.005, .01, .075, .14, .2`\n",
    "\n",
    "When the code is complete, plot your results using `matplotlib`, as you did in Homework 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Subgroup Fairness via Cost-Sensitive Reduction (20 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will implement models which are fair with respect to subgroups of a population, as described in [Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness](https://arxiv.org/abs/1711.05144v5) and in lecture: https://www.seas.upenn.edu/~cis399/files/lecture/l11.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, you should clone [GerryFair repository](https://github.com/algowatchpenn/GerryFair) from github and add the `gerryfair/` folder to the same directory as this notebook.\n",
    "\n",
    "You can run the following two cells to clone the repository and use the code to clean the dataset and provide three numpy arrays as outputs.\n",
    "\n",
    "You should note that the first cell also copies over a Jupyter notebook that demos the functionality of the codebase. **Before jumping into each section of this part, we advise that you run through the relevant part of the demo as well as read through the relevant part of the codebase.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUN THIS CELL\n",
    "## DO NOT MODIFY\n",
    "\n",
    "# This clones the the github repository into a local folder\n",
    "!git clone https://github.com/algowatchpenn/GerryFair.git ../GerryFair\n",
    "    \n",
    "# Copy the core code and the demo into the current folder.\n",
    "!mkdir gerryfair\n",
    "!cp -r ../GerryFair/gerryfair/. gerryfair/\n",
    "!cp ../GerryFair/GerryFair\\ Demo.ipynb gerryfair_demo.ipynb\n",
    "\n",
    "import gerryfair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Auditing a classifier (5 Points)\n",
    "\n",
    "Using the `gerryfair.model.Auditor` class, audit the predictions from Part 2 to find a subgroup that violates the fairness disparity metric. In this case, we will use false positive as our fairness disparity metric. The `audit` function may be helpful for finding a subgroup that violates the fairness metric and getting the fairness disparity. Print the fairness disparity for this subgroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2: Constructing a Subgroup Fair Classifier (5 Points)\n",
    "\n",
    "Now, you will construct a model which is fair with respect to all subgroups of the population. Using the `gerryfair.model.Model` class, create a classifier with the following parameters: set `gamma` to be .01, `max_iters` to be 20, and leave the rest to their default values.\n",
    "\n",
    "Train the model and create in-sample predictions for our data (Use all of `dataX`, `dataA`, and `dataY` for both training and testing). Print out the error of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3: Analysis of a Subgroup Fair Classifier (5 points)\n",
    "\n",
    "Now, let's audit the predictions of the new model. Similar to Section 3.2, use an auditor to find a group that violates the fairness disparity metric. Print out the fairness disparity for this group. How does it compare to the fairness disaprity of the previous model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4: Pareto Curve of a Subgroup Fair Classifier (5 points)\n",
    "\n",
    "By varying the parameter `gamma`, construct a pareto curve that measures the error of the classifier as the value of `gamma` changes. \n",
    "\n",
    "You will find the `pareto` function in `gerryfair.model.Model` helpful when doing this. It takes in `X`, `X_prime`, `y`, and `gamma_list`. `X`, `X_prime`, and `y` correspond to `dataX`, `dataA`, and `dataY`, while `gamma_list` should be a list containing the `gamma`'s you would like to use. You should also set parameter `max_iters` to be 20 again in this function. This function even creates the plot for you!\n",
    "\n",
    "Use the following values for `gamma`: `.005, .01, .075, .14, .2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Short Response Questions (25 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Below is a gif of a heatmap which shows how false positive disparity change for specific subgroups as the Learner and Auditor interact in each round. Each square represents a subgroup, the z-axis is the fairness disparity of that subgroup. What does it mean when the heatmap is \\\"flat\\\"?\n",
    "![heatmap](./heatmap.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please type your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Compare the error and gamma unfairness between the MSR and GerryFair code. What is a possible explanation for the differences or similarities?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please type your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Please complete [this survey](https://goo.gl/forms/Nqpdrpq9htgSbiHs2) on the user experience of using the GerryFair Code (In part 4). After you submit, please write the \\\"key phrase\\\" provided in the survey here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please type your answers here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** In Part 2, you should have seen that the error of the most fair pair of thresholds was much larger than the error for the best overall threshold. Suppose that you are allowed to randomize between thresholds, allowing you to achieve any TPR-FPR pair beneath the ROC curve for each group. Can you think of a better approach for maximizing accuracy while maintaining fairness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please type your answers here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** What do you think the relationship error of a fair classifier and the number of protected attributes is? That is, if we increase the number of protected attributes, do you think the error would increase, decrease, or stay the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please type your answers here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
